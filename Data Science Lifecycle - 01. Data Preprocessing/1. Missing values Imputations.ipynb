{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ecf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4050c0bf",
   "metadata": {},
   "source": [
    "# Handling the Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce59c4",
   "metadata": {},
   "source": [
    "### Function To find out Missing Values in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_na(data):\n",
    "    missing_values= data.isna().sum().reset_index()\n",
    "    missing_values.columns= [\"Features\", \"Missing_Values\"]\n",
    "    missing_values[\"Missing_Percent\"] = round(missing_values.Missing_Values/len(data)*100,2)\n",
    "    missing_values = missing_values[missing_values.Missing_Values > 0 ]\n",
    "\n",
    "    return missing_values.sort_values(\"Missing_Percent\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2f18e",
   "metadata": {},
   "source": [
    "# Types of missing data\n",
    "\n",
    "### 1. MCAR - (Missing completely at random)\n",
    "### 2. MNAR - (Missing data not at random)(Systematic missing)\n",
    "### 3. MAR - Missing at random\n",
    "------------------------------------------------------------------------------------------------------\n",
    "## 1. MCAR - (Missing completely at random)\n",
    "\n",
    "If probability of being missing is same for every observation which means their is no pattern in missing value. and hence *pattern of missing values* does not have any relationship whith any other variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6265b75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f378e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20b37b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN  \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc0a39",
   "metadata": {},
   "source": [
    "- **Embarked** this column has nothing to with any other variable hence it is the e.g. of MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a040a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Razi, Mr. Raihed</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2629</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "5              6         0       3                          Moran, Mr. James   \n",
       "17            18         1       2              Williams, Mr. Charles Eugene   \n",
       "19            20         1       3                   Masselmani, Mrs. Fatima   \n",
       "26            27         0       3                   Emir, Mr. Farred Chehab   \n",
       "28            29         1       3             O'Dwyer, Miss. Ellen \"Nellie\"   \n",
       "..           ...       ...     ...                                       ...   \n",
       "859          860         0       3                          Razi, Mr. Raihed   \n",
       "863          864         0       3         Sage, Miss. Dorothy Edith \"Dolly\"   \n",
       "868          869         0       3               van Melkebeke, Mr. Philemon   \n",
       "878          879         0       3                        Laleff, Mr. Kristo   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "\n",
       "        Sex  Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "5      male  NaN      0      0      330877   8.4583   NaN        Q  \n",
       "17     male  NaN      0      0      244373  13.0000   NaN        S  \n",
       "19   female  NaN      0      0        2649   7.2250   NaN        C  \n",
       "26     male  NaN      0      0        2631   7.2250   NaN        C  \n",
       "28   female  NaN      0      0      330959   7.8792   NaN        Q  \n",
       "..      ...  ...    ...    ...         ...      ...   ...      ...  \n",
       "859    male  NaN      0      0        2629   7.2292   NaN        C  \n",
       "863  female  NaN      8      2    CA. 2343  69.5500   NaN        S  \n",
       "868    male  NaN      0      0      345777   9.5000   NaN        S  \n",
       "878    male  NaN      0      0      349217   7.8958   NaN        S  \n",
       "888  female  NaN      1      2  W./C. 6607  23.4500   NaN        S  \n",
       "\n",
       "[158 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Age\"].isnull() & df[\"Cabin\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6551c0",
   "metadata": {},
   "source": [
    "- For almost every NaN value of **Age**, their NaN for **Cabin** also.\n",
    "- Here, **Age** & **Cabin** may having NaN values because those people from titanic were not alive to provide those data hence their is Relationship between Missing value of Age and Cabine as both of values can be assumed to be NAN because of same reason. hence **It is not a type of MCAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6e34b",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------\n",
    "## 2. MNAR - (Missing data not at random)(Systematic missing)\n",
    "\n",
    "When probability of being missing is not same for every instances for a variable and their is relationship data missing and any other variable.\n",
    "\n",
    "E.g. **Age**,**Cabin** have some relationship between them, because of which they both have NaN at many common instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f44287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cabin_null\"] = np.where(df[\"Cabin\"].isnull(), 1, 0)\n",
    "df[\"cabin_null\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7de2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Survived\"])[\"cabin_null\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e456a",
   "metadata": {},
   "source": [
    "From Survived people their is only 60% missing value but for people who not survived have 88% of missing values, Hence we can conclude that Missing value at Cabin is because those people could not survived."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4453f59",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------\n",
    "## 3. MAR - Missing at random\n",
    "\n",
    "e.g. Men hiding their salary, females hiding their age so salary and age variables are dependent on Sex feature but their is no relationship between which instance is missing so data is missing at random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ffcc0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19beda55",
   "metadata": {},
   "source": [
    "# Techniques of Handling the Missing Values\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "# 1.  For Continuos Missing Data\n",
    "\n",
    "### 1. Mean/Median/Mode Imputation\n",
    "### 2. Random Sample Imputation\n",
    "### 3. Capturing NAN values with a new feature\n",
    "### 4. End of Distribution imputation\n",
    "### 5. Abritrary value imputation\n",
    "------------------------------------------------------------------------\n",
    "# 2 For Categorical Missing Data\n",
    "\n",
    "### 1. Frequency category imputation \n",
    "### 2. Adding a variable to capture NAN\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05673f",
   "metadata": {},
   "source": [
    "# 1.  For Continuos Missing Data\n",
    "# 1.1. Mean/Median/Mode Imputation\n",
    "\n",
    "#### When to Use?\n",
    "- When Data is MCAR\n",
    "\n",
    "#### How?\n",
    "- Replace NaN by most frequent occurance of variable.\n",
    "- When their are concerned about outliers we should consider using Median of Mode  instead of Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a81a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Impute Null values with Mean, Median, Mode\n",
    "\n",
    "def missing_value_imputer(data, feature, method):\n",
    "    if method == \"mode\":\n",
    "        data[feature] = data[feature].fillna(data[feature].mode()[0])\n",
    "    elif method == \"median\":\n",
    "        data[feature] = data[feature].fillna(data[feature].median())\n",
    "    else:\n",
    "        data[feature] = data[feature].fillna(data[feature].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13da364",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/titanic_train.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dee2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176526dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9f5b8",
   "metadata": {},
   "source": [
    "### Age has 20% Missing data and Cabin has 77% Missing data, We can replace this with Median and Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867546f3",
   "metadata": {},
   "source": [
    "### Replacing Age with Median and Mode and See Standerd deviation which one lesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee521da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age_after\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "df[\"Age_after\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "df[\"Age\"].plot(kind=\"kde\", ax=ax)\n",
    "df[\"Age_after\"].plot(kind=\"kde\", ax=ax, color=\"red\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478d6b1",
   "metadata": {},
   "source": [
    "## Advantages of Mean/Median/Mode Imputation\n",
    "1. Easy and Quick to implementations\n",
    "2. Medians are Robust to Outliers (NOT MEAN)\n",
    "\n",
    "## Disadvantages of Mean/Median/Mode Imputation\n",
    "1. Change or Distortion in the original varience and standerd deviations. as we can see from above plot their is change in spread.\n",
    "2. It Impacts Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642ae70",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------\n",
    "# 1.2. Random Sample Imputation\n",
    "\n",
    "- It takes random observations/data instances and used them to replace NaN values.\n",
    "- It is used when data is missing completely at random(MCAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f721bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/titanic_train.csv'\n",
    "df = pd.read_csv(path, usecols=[\"Age\", \"Fare\",\"Survived\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32443848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan(df, variable):\n",
    "    \n",
    "    df[variable+\"_random\"] = df[variable]\n",
    "    \n",
    "    samples_without_Nan = df[variable].dropna()\n",
    "    \n",
    "    count_of_nan = df[variable].isnull().sum()\n",
    "    \n",
    "    random_samples = samples_without_Nan.sample(count_of_nan, random_state=0)\n",
    "    \n",
    "    random_samples.index = df[df[variable].isnull()].index\n",
    "        \n",
    "    df.loc[df[variable].isnull(), variable+\"_random\"] = random_samples\n",
    "    \n",
    "\n",
    "impute_nan(df, \"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf16451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age_random\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ae940",
   "metadata": {},
   "source": [
    "### Change in Standerd Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c016fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b03bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age_random\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf68f3",
   "metadata": {},
   "source": [
    "### Change in Density Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dddaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df[\"Age\"].plot(kind=\"kde\", label=\"Age\")\n",
    "df[\"Age_random\"].plot(kind=\"kde\", label=\"Age_random\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f0ffb",
   "metadata": {},
   "source": [
    "## From above We can see that standerd deviation and spread before and after the Random sample imputation does not give much difference as compare to Median imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862862f0",
   "metadata": {},
   "source": [
    "## Advantages of Mean/Median/Mode Imputation\n",
    "1. Easy and quicker to implement.\n",
    "2. Change in standerd deviation and spread is significantly lesser as compare to Median imputation.i.e. Less Distortion in variance.\n",
    "\n",
    "## Disadvantages of Mean/Median/Mode Imputation\n",
    "It cannot be used in every situation.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f28373",
   "metadata": {},
   "source": [
    "# 1.3. Capturing NAN values with a new feature\n",
    "\n",
    "- It works well if the data are not missing completely at random (MNAR)\n",
    "- It creates new feature that captures the importance of missingness or presentness of NaN value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/titanic_train.csv',usecols=[\"Age\", \"Fare\",\"Survived\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age_NaN\"] = np.where(df[\"Age\"].isnull(), 1, 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0394c",
   "metadata": {},
   "source": [
    "## That's it, We just create new feature which captures the wheather value is NaN or not and it will be accounted as new feature by model.\n",
    "\n",
    "- In case of this perticular titanic dataset, Absence of Age value will not be influencing the survival of person i.e. this new features have no impact on output hence we cannot use such feature in this case.\n",
    "\n",
    "- We can also create new feature that captures the missingness and replace the nulls with Mean/median imputations. So that new feature can capture the importance of missingness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44578a7f",
   "metadata": {},
   "source": [
    "## Advantages of Mean/Median/Mode Imputation\n",
    "1. Easy and quicker to implement.\n",
    "2. Creates new feature which captures missing ness or present of null value as feature.\n",
    "\n",
    "## Disadvantages of Mean/Median/Mode Imputation\n",
    "1. It cannot be used in every situation.\n",
    "2. causes curse of dimensionality.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {
    "std.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "72319c62",
   "metadata": {},
   "source": [
    "# 1.4. End of Distribution imputation\n",
    "\n",
    "- In this method we replace NaN values with values greater than or eqaul to greatest 3rd standerd deviation. Hence values are replaced with values which are far away.\n",
    "\n",
    "- It is used when their are outliers presents which are captered by this method.\n",
    "![std.png](attachment:std.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/titanic_train.csv',usecols=[\"Age\", \"Fare\",\"Survived\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bf883",
   "metadata": {},
   "source": [
    "### Here we can see the values which are far away can be considered from 70 or 75 those values are selected to replace with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpute_nan(df, variable):\n",
    "    extreme_val = df[variable].mean()+3*df[variable].std()\n",
    "    df[variable+\"_extreme\"] = df[variable].fillna(extreme_val)\n",
    "    df[variable+\"_median\"] = df[variable].fillna(df[variable].median())\n",
    "\n",
    "inpute_nan(df,\"Age\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ceb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "df[\"Age\"].hist()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "df[\"Age_median\"].hist()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "df[\"Age_extreme\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fa3ce",
   "metadata": {},
   "source": [
    "## To find which one better from Age_extreme and Age_median we draw BoxPlot to check outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(df[\"Age\"], data=df)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(df[\"Age_median\"], data=df)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(df[\"Age_extreme\"], data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df570ae",
   "metadata": {},
   "source": [
    "### We can See that their are almost no outliers present in Age_extreme hence it can be used over the Age_mediam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ed3fa",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1.5. Abritrary value imputations\n",
    "\n",
    " - It consist of replacing NaN with abritrary values, We can use Last outliers on both sides.\n",
    " - The Arbitrary value choosen should not be frequently present in data.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a59acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/titanic_train.csv',usecols=[\"Age\", \"Fare\",\"Survived\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpute_nan(df, variable):\n",
    "    extreme_val = df[variable].mean()+3*df[variable].std()\n",
    "    df[variable+\"_hundred\"] = df[variable].fillna(100)\n",
    "    df[variable+\"_zero\"] = df[variable].fillna(0)\n",
    "\n",
    "inpute_nan(df,\"Age\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "df[\"Age\"].hist()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "df[\"Age_hundred\"].hist()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "df[\"Age_zero\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae36f2b",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "1. Easy To implement\n",
    "\n",
    "2. Fater way to implement\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "1. Since we are using the more frequent labels, it may use them in an over respresented way, if there are many nan's\n",
    "\n",
    "2. It distorts the relation of the most frequent label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e215b",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------\n",
    "# 2 Categorical Missing Data\n",
    "\n",
    "# 2.1. Frequency category imputation - \n",
    "\n",
    "We just replace the Nulls with most frequent variable that is the mode of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460749ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/loan.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BsmtQual\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BsmtQual\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041ff71",
   "metadata": {},
   "source": [
    "#### **TA** can be taken as variable to replace at missing places in **BsmtQual** as it is most frequent in column.\n",
    "\n",
    "#### We can use mode() or value_counts() function to get  frequently occuring feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpute_nan(df, variable):\n",
    "    fre_category = df[variable].value_counts().index[0]     # or simply use mode()\n",
    "    df[variable] = df[variable].fillna(fre_category)\n",
    "    \n",
    "\n",
    "for i in df.columns:\n",
    "    inpute_nan(df, i)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c73e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce546522",
   "metadata": {},
   "source": [
    "## Advantages \n",
    "  Easy and quick.\n",
    "\n",
    "## Disadvantages\n",
    " 1.  We cannot use this method for large number of missing data otherwise it will bias the data.\n",
    " 2. Distort relations between most frequent labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290b8b1",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "## 2.2. Adding a variable feature to capture NAN\n",
    "\n",
    "- Similar to \"Capturing NAN values with a new feature\"\n",
    "- Add new feature that captures importance of missing value and replace missing values with Mode also.\n",
    "- **Use this techniques perticularly when their are many null values present.**\n",
    "\n",
    "- One of the most commenly used technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/loan.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213586d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtQual_Var']=np.where(df['BsmtQual'].isnull(),1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcaf56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['FireplaceQu_Var']=np.where(df['FireplaceQu'].isnull(),1,0)\n",
    "frequent=df['FireplaceQu'].mode()[0]\n",
    "df['FireplaceQu'].fillna(frequent,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1880a",
   "metadata": {},
   "source": [
    "## Advantages \n",
    "  Usefull when there are many Null values.\n",
    "\n",
    "## Disadvantages\n",
    "  Can cause problem due to many features additions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c83b9",
   "metadata": {},
   "source": [
    "#### Suppose if you have more frequent categories, we just replace NAN with a new category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Shubham/Documents/Data Science/Notebooks/00. Data_Store/loan.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90522990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan(df,variable):\n",
    "    df[variable+\"newvar\"]=np.where(df[variable].isnull(),\"Missing\",df[variable])\n",
    "    \n",
    "for feature in ['BsmtQual','FireplaceQu','GarageType']:\n",
    "    impute_nan(df,feature)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba139266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['BsmtQual','FireplaceQu','GarageType'],axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
